{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T11:51:28.921967Z",
     "iopub.status.busy": "2025-04-05T11:51:28.921447Z",
     "iopub.status.idle": "2025-04-05T11:53:01.585954Z",
     "shell.execute_reply": "2025-04-05T11:53:01.584538Z",
     "shell.execute_reply.started": "2025-04-05T11:51:28.921925Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!clearml-init\n",
    "\n",
    "from clearml import Task\n",
    "\n",
    "task = Task.init(project_name=\"CycleGAN Training\", task_name=\"Aivazovsky Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:17.500981Z",
     "iopub.status.busy": "2025-04-05T12:00:17.499229Z",
     "iopub.status.idle": "2025-04-05T12:00:21.001695Z",
     "shell.execute_reply": "2025-04-05T12:00:21.000974Z",
     "shell.execute_reply.started": "2025-04-05T12:00:17.500940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import deepspeed as ds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as L\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.utilities import CombinedLoader\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "logger = task.get_logger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:41.186552Z",
     "iopub.status.busy": "2025-04-05T12:00:41.184335Z",
     "iopub.status.idle": "2025-04-05T12:00:41.191049Z",
     "shell.execute_reply": "2025-04-05T12:00:41.189805Z",
     "shell.execute_reply.started": "2025-04-05T12:00:41.186518Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_CONFIG = {\n",
    "    \"style_dir\": os.path.join(\"/kaggle/input/cyclegan-dataset/aivazovsky\", \"*.jpg\"),\n",
    "    \"photo_dir\": os.path.join(\"/kaggle/input/cyclegan-dataset/real\", \"*.jpg\"),\n",
    "    \"batch_size\": 1,\n",
    "    \"sample_size\": 5,\n",
    "    \"config\": {\n",
    "        \"num_workers\": os.cpu_count(),\n",
    "        \"pin_memory\": True,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:42.699048Z",
     "iopub.status.busy": "2025-04-05T12:00:42.698708Z",
     "iopub.status.idle": "2025-04-05T12:00:42.704414Z",
     "shell.execute_reply": "2025-04-05T12:00:42.703576Z",
     "shell.execute_reply.started": "2025-04-05T12:00:42.699019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImageTransform(object):\n",
    "    def __init__(self, dim=256):\n",
    "\n",
    "        self.resize = T.Resize((dim, dim), antialias=True)\n",
    "        self.train_transform = T.Compose(\n",
    "            [\n",
    "                T.Resize((dim, dim), antialias=True),\n",
    "                T.RandomCrop((dim, dim)),\n",
    "                T.RandomHorizontalFlip(p=0.5),\n",
    "                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, image, stage):\n",
    "        if stage == \"fit\":\n",
    "            img = self.train_transform(image)\n",
    "        else:\n",
    "            img = self.resize(image)\n",
    "\n",
    "        return img * 2 - 1  # normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:44.557487Z",
     "iopub.status.busy": "2025-04-05T12:00:44.557167Z",
     "iopub.status.idle": "2025-04-05T12:00:44.562356Z",
     "shell.execute_reply": "2025-04-05T12:00:44.561467Z",
     "shell.execute_reply.started": "2025-04-05T12:00:44.557460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DatasetBlock(Dataset):\n",
    "    def __init__(self, filenames, transform, stage):\n",
    "        self.filenames = filenames\n",
    "        self.transform = transform\n",
    "        self.stage = stage\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = read_image(self.filenames[idx]) / 255.0\n",
    "        return self.transform(img, stage=self.stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:46.224540Z",
     "iopub.status.busy": "2025-04-05T12:00:46.224213Z",
     "iopub.status.idle": "2025-04-05T12:00:46.231734Z",
     "shell.execute_reply": "2025-04-05T12:00:46.230975Z",
     "shell.execute_reply.started": "2025-04-05T12:00:46.224512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ToStyleModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        style_dir,\n",
    "        photo_dir,\n",
    "        config,\n",
    "        sample_size,\n",
    "        batch_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.sample_size = sample_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.style_filenames = glob.glob(style_dir)\n",
    "        self.photo_filenames = glob.glob(photo_dir)\n",
    "\n",
    "        self.transform = ImageTransform()\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "            self.style_training = DatasetBlock(\n",
    "                self.style_filenames, self.transform, stage\n",
    "            )\n",
    "            self.photo_training = DatasetBlock(\n",
    "                self.photo_filenames, self.transform, stage\n",
    "            )\n",
    "\n",
    "        if stage in [\"fit\", \"test\", \"predict\"]:\n",
    "            self.photo_validation = DatasetBlock(\n",
    "                self.photo_filenames, self.transform, None\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        config = {\n",
    "            \"shuffle\": True,\n",
    "            \"drop_last\": True,\n",
    "            \"batch_size\": self.batch_size,\n",
    "            **self.config,\n",
    "        }\n",
    "\n",
    "        style_loader = DataLoader(self.style_training, **config)\n",
    "        photo_loader = DataLoader(self.photo_training, **config)\n",
    "        loaders = {\"style\": style_loader, \"photo\": photo_loader}\n",
    "\n",
    "        return CombinedLoader(loaders, mode=\"max_size_cycle\")\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.photo_validation,\n",
    "            batch_size=self.sample_size,\n",
    "            **self.config,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.val_dataloader()\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.photo_validation,\n",
    "            batch_size=self.batch_size,\n",
    "            **self.config,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:48.635715Z",
     "iopub.status.busy": "2025-04-05T12:00:48.635378Z",
     "iopub.status.idle": "2025-04-05T12:00:49.427543Z",
     "shell.execute_reply": "2025-04-05T12:00:49.424885Z",
     "shell.execute_reply.started": "2025-04-05T12:00:48.635688Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dm_sample = ToStyleModule(**DATA_CONFIG)\n",
    "dm_sample.setup(\"fit\")\n",
    "\n",
    "train_loader = dm_sample.train_dataloader()\n",
    "imgs = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN components\n",
    "## Downsampling, Upsampling and Resudual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:51.680547Z",
     "iopub.status.busy": "2025-04-05T12:00:51.680120Z",
     "iopub.status.idle": "2025-04-05T12:00:51.687221Z",
     "shell.execute_reply": "2025-04-05T12:00:51.686323Z",
     "shell.execute_reply.started": "2025-04-05T12:00:51.680511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Downsampling(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel=4,\n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        lrelu=True,\n",
    "        norm=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                bias=not norm,\n",
    "            )\n",
    "        )\n",
    "        if norm:\n",
    "            self.conv_block.append(nn.InstanceNorm2d(out_channels, affine=True))\n",
    "\n",
    "        if lrelu is not None:\n",
    "            self.conv_block.append(nn.LeakyReLU(0.2, True) if lrelu else nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:52.480025Z",
     "iopub.status.busy": "2025-04-05T12:00:52.479702Z",
     "iopub.status.idle": "2025-04-05T12:00:52.485108Z",
     "shell.execute_reply": "2025-04-05T12:00:52.484405Z",
     "shell.execute_reply.started": "2025-04-05T12:00:52.479995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Upsampling(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel=4,\n",
    "        stride=2,\n",
    "        padding=1,\n",
    "        output_padding=0,\n",
    "        dropout=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=kernel,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                output_padding=output_padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "        )\n",
    "\n",
    "        if dropout:\n",
    "            self.block.append(nn.Dropout(0.5))\n",
    "        self.block.append(nn.ReLU(True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:54.616706Z",
     "iopub.status.busy": "2025-04-05T12:00:54.616386Z",
     "iopub.status.idle": "2025-04-05T12:00:54.621498Z",
     "shell.execute_reply": "2025-04-05T12:00:54.620754Z",
     "shell.execute_reply.started": "2025-04-05T12:00:54.616681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channels, kernel=3, padding=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(padding),\n",
    "            Downsampling(\n",
    "                in_channels,\n",
    "                in_channels,\n",
    "                kernel=kernel,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                lrelu=False,\n",
    "            ),\n",
    "            nn.ReflectionPad2d(padding),\n",
    "            Downsampling(\n",
    "                in_channels, in_channels, kernel=kernel, stride=1, padding=0, lrelu=None\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:56.276564Z",
     "iopub.status.busy": "2025-04-05T12:00:56.276262Z",
     "iopub.status.idle": "2025-04-05T12:00:56.284321Z",
     "shell.execute_reply": "2025-04-05T12:00:56.283393Z",
     "shell.execute_reply.started": "2025-04-05T12:00:56.276540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, hidden_channels, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsampling_block = nn.Sequential(\n",
    "            Downsampling(\n",
    "                in_channels, hidden_channels, norm=False\n",
    "            ),  # 64x128x128 out_channels-height-width\n",
    "            Downsampling(hidden_channels, hidden_channels * 2),  # 128x64x64\n",
    "            Downsampling(hidden_channels * 2, hidden_channels * 4),  # 256x32x32\n",
    "            Downsampling(hidden_channels * 4, hidden_channels * 8),  # 512x16x16\n",
    "            Downsampling(hidden_channels * 8, hidden_channels * 8),  # 512x8x8\n",
    "            Downsampling(hidden_channels * 8, hidden_channels * 8),  # 512x4x4\n",
    "            Downsampling(hidden_channels * 8, hidden_channels * 8),  # 512x2x2\n",
    "            Downsampling(hidden_channels * 8, hidden_channels * 8, norm=False),\n",
    "            # 512x1x1, instance norm does not work on 1x1\n",
    "        )\n",
    "\n",
    "        self.upsampling_block = nn.Sequential(\n",
    "            Upsampling(\n",
    "                hidden_channels * 8, hidden_channels * 8, dropout=True\n",
    "            ),  # (512+512)x2x2\n",
    "            Upsampling(\n",
    "                hidden_channels * 16, hidden_channels * 8, dropout=True\n",
    "            ),  # (512+512)x4x4\n",
    "            Upsampling(\n",
    "                hidden_channels * 16, hidden_channels * 8, dropout=True\n",
    "            ),  # (512+512)x8x8\n",
    "            Upsampling(hidden_channels * 16, hidden_channels * 8),  # (512+512)x16x16\n",
    "            Upsampling(hidden_channels * 16, hidden_channels * 4),  # (256+256)x32x32\n",
    "            Upsampling(hidden_channels * 8, hidden_channels * 2),  # (128+128)x64x64\n",
    "            Upsampling(hidden_channels * 4, hidden_channels),  # (64+64)x128x128\n",
    "        )\n",
    "\n",
    "        self.feature_block = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                hidden_channels * 2, out_channels, kernel_size=4, stride=2, padding=1\n",
    "            ),  # 3x256x256\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = []\n",
    "\n",
    "        for down in self.downsampling_block:\n",
    "            x = down(x)\n",
    "            skips.append(x)\n",
    "        skips = reversed(skips[:-1])\n",
    "\n",
    "        for up, skip in zip(self.upsampling_block, skips):\n",
    "            x = up(x)\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "\n",
    "        return self.feature_block(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:00:58.516688Z",
     "iopub.status.busy": "2025-04-05T12:00:58.516345Z",
     "iopub.status.idle": "2025-04-05T12:00:58.522968Z",
     "shell.execute_reply": "2025-04-05T12:00:58.522007Z",
     "shell.execute_reply.started": "2025-04-05T12:00:58.516659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, hidden_channels, in_channels, out_channels, num_resblocks):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            Downsampling(\n",
    "                in_channels, hidden_channels, kernel=7, stride=1, padding=0, lrelu=False\n",
    "            ),  # 64x256x256\n",
    "            Downsampling(\n",
    "                hidden_channels, hidden_channels * 2, kernel=3, lrelu=False\n",
    "            ),  # 128x128x128\n",
    "            Downsampling(\n",
    "                hidden_channels * 2, hidden_channels * 4, kernel=3, lrelu=False\n",
    "            ),  # 256x64x64\n",
    "            # residual blocks\n",
    "            *[Residual(hidden_channels * 4) for _ in range(num_resblocks)],  # 256x64x64\n",
    "            # upsampling path\n",
    "            Upsampling(\n",
    "                hidden_channels * 4, hidden_channels * 2, kernel=3, output_padding=1\n",
    "            ),  # 128x128x128\n",
    "            Upsampling(\n",
    "                hidden_channels * 2, hidden_channels, kernel=3, output_padding=1\n",
    "            ),  # 64x256x256\n",
    "            nn.ReflectionPad2d(3),  # to handle border pixels\n",
    "            nn.Conv2d(\n",
    "                hidden_channels, out_channels, kernel_size=7, stride=1, padding=0\n",
    "            ),  # 3x256x256\n",
    "            nn.Tanh(),  # pixels in the range [-1,1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:01:00.496075Z",
     "iopub.status.busy": "2025-04-05T12:01:00.495769Z",
     "iopub.status.idle": "2025-04-05T12:01:00.500980Z",
     "shell.execute_reply": "2025-04-05T12:01:00.500294Z",
     "shell.execute_reply.started": "2025-04-05T12:01:00.496052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(\n",
    "        self, name, hidden_channels, num_resblocks, in_channels=3, out_channels=3\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_resblocks = num_resblocks\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def create(self):\n",
    "        if self.name == \"unet\":\n",
    "            return UNet(self.hidden_channels, self.in_channels, self.out_channels)\n",
    "\n",
    "        elif self.name == \"resnet\":\n",
    "            return ResNet(\n",
    "                self.hidden_channels,\n",
    "                self.in_channels,\n",
    "                self.out_channels,\n",
    "                self.num_resblocks,\n",
    "            )\n",
    "\n",
    "        return \"Did not find generator\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:01:02.426550Z",
     "iopub.status.busy": "2025-04-05T12:01:02.426229Z",
     "iopub.status.idle": "2025-04-05T12:01:02.431472Z",
     "shell.execute_reply": "2025-04-05T12:01:02.430746Z",
     "shell.execute_reply.started": "2025-04-05T12:01:02.426527Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_channels, in_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            Downsampling(in_channels, hidden_channels, norm=False),  # 64x128x128\n",
    "            Downsampling(hidden_channels, hidden_channels * 2),  # 128x64x64\n",
    "            Downsampling(hidden_channels * 2, hidden_channels * 4),  # 256x32x32\n",
    "            Downsampling(\n",
    "                hidden_channels * 4, hidden_channels * 8, stride=1\n",
    "            ),  # 512x31x31\n",
    "            nn.Conv2d(\n",
    "                hidden_channels * 8, 1, kernel_size=4, padding=1\n",
    "            ),  # 1x30x30 (num_channels-h-w)\n",
    "        )  # 1 channel for binary classification task, 30-30 spatial dimensions of the feature map\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:01:03.870348Z",
     "iopub.status.busy": "2025-04-05T12:01:03.869990Z",
     "iopub.status.idle": "2025-04-05T12:01:03.876649Z",
     "shell.execute_reply": "2025-04-05T12:01:03.875687Z",
     "shell.execute_reply.started": "2025-04-05T12:01:03.870316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, max_size):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.current_capacity = 0\n",
    "\n",
    "    def __call__(self, images):\n",
    "        if self.max_size == 0:\n",
    "            return images\n",
    "\n",
    "        imgs = []\n",
    "        for img in images:\n",
    "            img = img.unsqueeze(dim=0)\n",
    "\n",
    "            if self.current_capacity < self.max_size:\n",
    "                self.current_capacity += 1\n",
    "                self.buffer.append(img)\n",
    "                imgs.append(img)\n",
    "            else:\n",
    "                p = np.random.uniform(low=0.0, high=1.0)\n",
    "\n",
    "                if p > 0.5:\n",
    "                    idx = np.random.randint(low=0, high=self.max_size)\n",
    "                    tmp = self.buffer[idx].clone()\n",
    "                    self.buffer[idx] = img\n",
    "                    imgs.append(tmp)\n",
    "                else:\n",
    "                    imgs.append(img)\n",
    "\n",
    "        return torch.cat(imgs, dim=0) if len(imgs) > 0 else images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:01:08.536417Z",
     "iopub.status.busy": "2025-04-05T12:01:08.536062Z",
     "iopub.status.idle": "2025-04-05T12:01:08.541260Z",
     "shell.execute_reply": "2025-04-05T12:01:08.540452Z",
     "shell.execute_reply.started": "2025-04-05T12:01:08.536388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_img(img_tensor, nrow, title=\"\"):\n",
    "    img_tensor = img_tensor.detach().cpu() * 0.5 + 0.5\n",
    "    img_grid = make_grid(img_tensor, nrow=nrow).permute(1, 2, 0)\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.imshow(img_grid)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:01:10.830030Z",
     "iopub.status.busy": "2025-04-05T12:01:10.829725Z",
     "iopub.status.idle": "2025-04-05T12:01:10.852519Z",
     "shell.execute_reply": "2025-04-05T12:01:10.851550Z",
     "shell.execute_reply.started": "2025-04-05T12:01:10.830007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CycleGAN(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        num_resblocks,\n",
    "        hidden_channels,\n",
    "        optimizer,\n",
    "        lr,\n",
    "        betas,\n",
    "        lambda_idt,\n",
    "        lambda_cycle,\n",
    "        buffer_max_size,\n",
    "        num_epochs,\n",
    "        decay_epochs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.save_hyperparameters(ignore=[\"optimizer\"])\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        self.G_PS = Generator(name, hidden_channels, num_resblocks).create()\n",
    "        self.G_SP = Generator(name, hidden_channels, num_resblocks).create()\n",
    "\n",
    "        self.D_P = Discriminator(hidden_channels)\n",
    "        self.D_S = Discriminator(hidden_channels)\n",
    "\n",
    "        self.fake_P_buffer = ReplayBuffer(buffer_max_size)\n",
    "        self.fake_S_buffer = ReplayBuffer(buffer_max_size)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.G_PS(img)\n",
    "\n",
    "    def init_weights(self):\n",
    "        def init_fn(m):\n",
    "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.InstanceNorm2d)):\n",
    "                nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "        for net in [self.G_PS, self.G_SP, self.D_S, self.D_P]:\n",
    "            net.apply(init_fn)\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "            self.init_weights()\n",
    "\n",
    "    def get_lr_scheduler(self, optimizer):\n",
    "\n",
    "        def lr_lambda(epoch):\n",
    "            len_decay_phase = self.hparams.num_epochs - self.hparams.decay_epochs + 1.0\n",
    "            curr_decay_step = max(0, epoch - self.hparams.decay_epochs + 1.0)\n",
    "            val = 1.0 - curr_decay_step / len_decay_phase\n",
    "\n",
    "            return max(0.0, val)\n",
    "\n",
    "        return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_config = {\"lr\": self.hparams.lr, \"betas\": self.hparams.betas}\n",
    "\n",
    "        optimizer_G = self.optimizer(\n",
    "            list(self.G_PS.parameters()) + list(self.G_SP.parameters()),\n",
    "            **optimizer_config,\n",
    "        )\n",
    "        optimizer_D = self.optimizer(\n",
    "            list(self.D_S.parameters()) + list(self.D_P.parameters()),\n",
    "            **optimizer_config,\n",
    "        )\n",
    "\n",
    "        optimizers = [optimizer_G, optimizer_D]\n",
    "        schedulers = [self.get_lr_scheduler(opt) for opt in optimizers]\n",
    "\n",
    "        return optimizers, schedulers\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.real_S = batch[\"style\"]\n",
    "        self.real_P = batch[\"photo\"]\n",
    "        opt_gen, opt_disc = self.optimizers()\n",
    "\n",
    "        self.fake_S = self.G_PS(self.real_P)\n",
    "        self.fake_P = self.G_SP(self.real_S)\n",
    "\n",
    "        self.idt_S = self.G_PS(self.real_S)\n",
    "        self.idt_P = self.G_SP(self.real_P)\n",
    "\n",
    "        self.recon_S = self.G_PS(self.fake_P)\n",
    "        self.recon_P = self.G_SP(self.fake_S)\n",
    "\n",
    "        # train generators\n",
    "        self.toggle_optimizer(opt_gen)\n",
    "        gen_loss = self.get_gen_loss()\n",
    "        opt_gen.zero_grad()\n",
    "        self.manual_backward(gen_loss)\n",
    "        opt_gen.step()\n",
    "        self.untoggle_optimizer(opt_gen)\n",
    "\n",
    "        self.toggle_optimizer(opt_disc)\n",
    "        disc_loss_S = self.get_disc_loss_S()\n",
    "        disc_loss_P = self.get_disc_loss_P()\n",
    "        opt_disc.zero_grad()\n",
    "        self.manual_backward(disc_loss_S)\n",
    "        self.manual_backward(disc_loss_P)\n",
    "        opt_disc.step()\n",
    "        self.untoggle_optimizer(opt_disc)\n",
    "\n",
    "        # record training losses\n",
    "\n",
    "        metrics = {\n",
    "            \"gen_loss\": gen_loss,\n",
    "            \"disc_loss_S\": disc_loss_S,\n",
    "            \"disc_loss_P\": disc_loss_P,\n",
    "        }\n",
    "        self.log_dict(metrics, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def get_cycle_loss(self, real, recon, lambda_cycle):\n",
    "        cycle_loss = F.l1_loss(recon, real)\n",
    "        return lambda_cycle * cycle_loss\n",
    "\n",
    "    def get_adv_loss(self, fake, disc):\n",
    "        fake_hat = disc(fake)\n",
    "        real_labels = torch.ones_like(fake_hat)\n",
    "        adv_loss = F.mse_loss(fake_hat, real_labels)\n",
    "        return adv_loss\n",
    "\n",
    "    def get_idt_loss(self, real, idt, lambda_cycle):\n",
    "        idt_loss = F.l1_loss(idt, real)\n",
    "        return self.hparams.lambda_idt * lambda_cycle * idt_loss\n",
    "\n",
    "    def get_gen_loss(self):\n",
    "        # calculate adversarial loss\n",
    "        adv_loss_PS = self.get_adv_loss(self.fake_S, self.D_S)\n",
    "        adv_loss_SP = self.get_adv_loss(self.fake_P, self.D_P)\n",
    "        total_adv_loss = adv_loss_PS + adv_loss_SP\n",
    "\n",
    "        # calculate identity loss\n",
    "        lambda_cycle = self.hparams.lambda_cycle\n",
    "        idt_loss_SS = self.get_idt_loss(self.real_S, self.idt_S, lambda_cycle[0])\n",
    "        idt_loss_PP = self.get_idt_loss(self.real_P, self.idt_P, lambda_cycle[1])\n",
    "        total_idt_loss = idt_loss_SS + idt_loss_PP\n",
    "\n",
    "        # calculate cycle loss\n",
    "        cycle_loss_SPS = self.get_cycle_loss(self.real_S, self.recon_S, lambda_cycle[0])\n",
    "        cycle_loss_PSP = self.get_cycle_loss(self.real_P, self.recon_P, lambda_cycle[1])\n",
    "        total_cycle_loss = cycle_loss_SPS + cycle_loss_PSP\n",
    "\n",
    "        # combine losses\n",
    "        gen_loss = total_adv_loss + total_idt_loss + total_cycle_loss\n",
    "        return gen_loss\n",
    "\n",
    "    def get_disc_loss(self, real, fake, disc):\n",
    "        real_hat = disc(real)\n",
    "        real_labels = torch.ones_like(real_hat)\n",
    "        real_loss = F.mse_loss(real_hat, real_labels)\n",
    "\n",
    "        fake_hat = disc(fake.detach())\n",
    "        fake_labels = torch.zeros_like(fake_hat)\n",
    "        fake_loss = F.mse_loss(fake_hat, fake_labels)\n",
    "\n",
    "        disc_loss = (fake_loss + real_loss) * 0.5\n",
    "        return disc_loss\n",
    "\n",
    "    def get_disc_loss_S(self):\n",
    "        fake_S = self.fake_S_buffer(self.fake_S)\n",
    "        return self.get_disc_loss(self.real_S, fake_S, self.D_S)\n",
    "\n",
    "    def get_disc_loss_P(self):\n",
    "        fake_P = self.fake_P_buffer(self.fake_P)\n",
    "        return self.get_disc_loss(self.real_P, fake_P, self.D_P)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.display_results(batch, batch_idx, \"validate\")\n",
    "\n",
    "    def display_results(self, batch, batch_idx, stage):\n",
    "        real_P = batch\n",
    "        fake_S = self(real_P)\n",
    "\n",
    "        if stage == \"validate\":\n",
    "            title = f\"Epoch {self.current_epoch + 1}: Photo-to-Style Translation\"\n",
    "        else:\n",
    "            title = f\"Sample {batch_idx + 1}: Photo-to-Style Translation\"\n",
    "\n",
    "        show_img(\n",
    "            torch.cat([real_P, fake_S], dim=0),\n",
    "            nrow=len(real_P),\n",
    "            title=title,\n",
    "        )\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        curr_lr = self.lr_schedulers()[0].get_last_lr()[0]\n",
    "        self.log(\"lr\", curr_lr, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        logger.report_scalar(\n",
    "            \"Learning Rate\", \"train\", value=curr_lr, iteration=self.current_epoch\n",
    "        )\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        avg_gen_loss = self.trainer.callback_metrics[\"gen_loss\"].item()\n",
    "        avg_disc_loss_S = self.trainer.callback_metrics[\"disc_loss_S\"].item()\n",
    "        avg_disc_loss_P = self.trainer.callback_metrics[\"disc_loss_P\"].item()\n",
    "\n",
    "        logger.report_scalar(\n",
    "            \"Generator Loss\",\n",
    "            \"epoch_avg\",\n",
    "            value=avg_gen_loss,\n",
    "            iteration=self.current_epoch,\n",
    "        )\n",
    "        logger.report_scalar(\n",
    "            \"Discriminator Loss (S)\",\n",
    "            \"epoch_avg\",\n",
    "            value=avg_disc_loss_S,\n",
    "            iteration=self.current_epoch,\n",
    "        )\n",
    "        logger.report_scalar(\n",
    "            \"Discriminator Loss (P)\",\n",
    "            \"epoch_avg\",\n",
    "            value=avg_disc_loss_P,\n",
    "            iteration=self.current_epoch,\n",
    "        )\n",
    "\n",
    "        for sch in self.lr_schedulers():\n",
    "            sch.step()\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {self.current_epoch + 1}\",\n",
    "            f\"gen_loss: {avg_gen_loss:.5f}\",\n",
    "            f\"disc_loss_S: {avg_disc_loss_S:.5f}\",\n",
    "            f\"disc_loss_P: {avg_disc_loss_P:.5f}\",\n",
    "            sep=\" - \",\n",
    "        )\n",
    "\n",
    "    def on_train_end(self):\n",
    "        print(\"Training ended.\")\n",
    "\n",
    "    def on_predict_epoch_end(self):\n",
    "        predictions = self.trainer.predict_loop.predictions\n",
    "        num_batches = len(predictions)\n",
    "        batch_size = predictions[0].shape[0]\n",
    "        last_batch_diff = batch_size - predictions[-1].shape[0]\n",
    "        print(\n",
    "            f\"Number of images generated: {num_batches * batch_size - last_batch_diff}.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:01:14.890274Z",
     "iopub.status.busy": "2025-04-05T12:01:14.889925Z",
     "iopub.status.idle": "2025-04-05T12:01:14.894697Z",
     "shell.execute_reply": "2025-04-05T12:01:14.893963Z",
     "shell.execute_reply.started": "2025-04-05T12:01:14.890245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_CONFIG = {\n",
    "    \"name\": \"unet\",\n",
    "    \"num_resblocks\": 9,\n",
    "    \"hidden_channels\": 64,\n",
    "    \"optimizer\": (\n",
    "        ds.ops.adam.FusedAdam if torch.cuda.is_available() else torch.optim.Adam\n",
    "    ),\n",
    "    \"lr\": 2e-4,\n",
    "    \"betas\": (0.5, 0.999),\n",
    "    \"lambda_idt\": 0.5,\n",
    "    \"lambda_cycle\": (10, 10),  # (MPM direction, PMP direction)\n",
    "    \"buffer_max_size\": 100,\n",
    "    \"num_epochs\": 20,\n",
    "    \"decay_epochs\": 20,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:01:35.785947Z",
     "iopub.status.busy": "2025-04-05T12:01:35.785519Z",
     "iopub.status.idle": "2025-04-05T12:01:35.822019Z",
     "shell.execute_reply": "2025-04-05T12:01:35.820994Z",
     "shell.execute_reply.started": "2025-04-05T12:01:35.785911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"/kaggle/working/\",\n",
    "    filename=\"epoch-{epoch:02d}\",\n",
    "    save_top_k=-1,\n",
    "    save_last=True,\n",
    "    every_n_epochs=5,\n",
    ")\n",
    "\n",
    "TRAIN_CONFIG = {\n",
    "    \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"precision\": \"16-mixed\" if torch.cuda.is_available() else 32,\n",
    "    \"devices\": 1,\n",
    "    \"enable_checkpointing\": True,\n",
    "    \"max_epochs\": MODEL_CONFIG[\"num_epochs\"],\n",
    "    \"limit_train_batches\": 1.0,\n",
    "    \"limit_predict_batches\": 1.0,\n",
    "    \"max_time\": {\"hours\": 4, \"minutes\": 55},\n",
    "    \"limit_val_batches\": 1,\n",
    "    \"limit_test_batches\": 5,\n",
    "    \"num_sanity_val_steps\": 0,\n",
    "    \"check_val_every_n_epoch\": 1,\n",
    "    \"callbacks\": [checkpoint_callback],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T12:01:38.127063Z",
     "iopub.status.busy": "2025-04-05T12:01:38.126762Z",
     "iopub.status.idle": "2025-04-05T16:45:56.982942Z",
     "shell.execute_reply": "2025-04-05T16:45:56.982189Z",
     "shell.execute_reply.started": "2025-04-05T12:01:38.127039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dm = ToStyleModule(**DATA_CONFIG)\n",
    "model = CycleGAN(**MODEL_CONFIG)\n",
    "trainer = L.Trainer(**TRAIN_CONFIG)\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6985130,
     "sourceId": 11284428,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
